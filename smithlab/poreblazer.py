"""
Copyright 2025. Brandon C. Tapia

MIT License
"""

import os
import numpy as np


def write_xyz(lammps_in, xyz_out="system.xyz"):
    """
    Writes an XYZ file from a LAMMPS data file (atom_style full),
    formatted for use with PoreBlazer.
    """

    atom_section = False
    atom_lines = []

    with open(lammps_in, "r", encoding="utf-8") as file:
        lines = file.readlines()

    for i, line in enumerate(lines):
        stripped = line.strip()
        columns = stripped.split()

        if stripped.startswith("Atoms"):
            atom_section = True
            continue

        if atom_section:
            if not columns:
                continue
            if columns[0].isalpha():
                break
            atom_lines.append(columns)

    with open(xyz_out, "w", encoding="utf-8") as file:
        file.write(f"{len(atom_lines)}\n")
        file.write("Generated by smithlab.poreblazer.write_xyz\n")
        for cols in atom_lines:
            atom_type = cols[2]
            x, y, z = cols[4], cols[5], cols[6]
            file.write(f"{atom_type} {x} {y} {z}\n")

    return


def write_forcefield(lammps_in, ff_out="ff.atoms"):

    mass_section = False
    pair_section = False

    kB = 1.9872e-3  # kcal/mol-K

    identifiers = []
    molwt = []
    energies = []
    sigma = []

    with open(lammps_in, "r", encoding="utf-8") as file:
        lines = file.readlines()

    for i, line in enumerate(lines):
        stripped = line.strip()
        columns = stripped.split()

        if stripped.startswith("Masses"):
            mass_section = True
            continue

        if stripped.startswith("Pair Coeffs"):
            pair_section = True
            mass_section = False
            continue

        if mass_section:
            if not columns:
                continue
            if columns[0].isalpha():
                mass_section = False
                continue

            identifiers.append(columns[0])
            molwt.append(columns[1])

        if pair_section:
            if not columns:
                continue
            if columns[0].isalpha():
                break

            energies.append(float(columns[1]) / kB)

            sigma.append(columns[2])

    with open(ff_out, "w", encoding="utf-8") as file:
        file.write(f"{len(identifiers)}\n")

        for i, identifier in enumerate(identifiers):
            file.write(
                f"{identifier} {float(sigma[i]):.4f} {float(energies[i]):.2f} {float(molwt[i]):.3f}\n"
            )

        file.write("! name of framework atom, diameter (LJ sigma) in A, epsilon in K, mol weight\n")

    return


def write_defaults(defaults="defaults.dat", settings=None):

    if settings is None:
        settings = {}

    ff = settings.setdefault("ff", "ff.atoms")
    he_D = settings.setdefault("he_D", 2.58)
    he_e = settings.setdefault("he_e", 10.22)
    he_T = settings.setdefault("he_T", 298)
    he_cutoff = settings.setdefault("he_cutoff", 12.8)
    probe_D = settings.setdefault("probe_D", 3.314)
    trials = settings.setdefault("trials", 500)
    cubelet_size = settings.setdefault("cubelet_size", 0.2)
    largest_pore_D = settings.setdefault("largest_pore_D", 15)
    bin_size = settings.setdefault("bin_size", 0.25)
    rand_num = settings.setdefault("rand_num", 21908391)
    vis_network = settings.setdefault("vis_network", 0)

    with open(defaults, "w", encoding="utf-8") as file:
        file.write(
            f"{ff}\n{he_D}, {he_e}, {he_T}, {he_cutoff}\n{probe_D}\n{trials}\n{cubelet_size}\n{largest_pore_D}, {bin_size}\n{rand_num}\n{vis_network}\n\n"
        )
        file.write("! Default forcefield\n")
        file.write(
            "! Helium atom sigma (A), helium atom epsilon (K), temperature (K), cutoff distance (A)\n"
        )
        file.write("! Probe atom sigma (A)\n")
        file.write("! Number of samples per atom for the surface area calculation\n")
        file.write("! Cubelet size (A)\n")
        file.write("! Largest anticipated pore diameter (A), size of the bin for PSD (A)\n")
        file.write("! Random number seed\n")
        file.write("! Visualization options: 1 -xyz, 2 - grd, 3 - both; 0 - none\n\n")
        file.write("! Do not change these values unless you know what you are doing\n")

    return


def write_input(lammps_in, input="input.dat", xyz_out="system.xyz"):

    count = 0
    with open(lammps_in, "r", encoding="utf-8") as file:
        lines = file.readlines()

    for line in lines:
        stripped = line.strip()
        columns = stripped.split()

        if stripped.endswith("xhi"):
            x_length = float(columns[1]) - float(columns[0])
            count += 1
        elif stripped.endswith("yhi"):
            y_length = float(columns[1]) - float(columns[0])
            count += 1
        elif stripped.endswith("zhi"):
            z_length = float(columns[1]) - float(columns[0])
            count += 1

        if count == 3:
            break

    with open(input, "w", encoding="utf-8") as file:
        file.write(f"{xyz_out}\n{x_length} {y_length} {z_length}\n90 90 90")

    return


def setup_pb(
    lammps_in,
    settings=None,
    xyz="system.xyz",
    ff_out="ff.atoms",
    defaults="defaults.dat",
    input_file="input.dat",
):

    write_xyz(lammps_in, xyz)
    write_forcefield(lammps_in, ff_out)
    write_defaults(defaults, settings)
    write_input(lammps_in, input_file, "system.xyz")  # TODO: allow for path if needed

    return


def get_data(prop, file_in="summary.dat", network=False):

    in_total = False
    in_network = False
    # print(file_in)

    with open(file_in, "r", encoding="utf-8") as file:
        lines = file.readlines()

    for _, line in enumerate(lines):

        stripped = line.strip()
        columns = stripped.split()

        if stripped.startswith("Total"):
            in_total = True

        if stripped.startswith("Network-accessible"):
            in_network = True
            in_total = False

        if in_total and network:
            continue

        if in_network and not network:
            continue

        if stripped.startswith(prop):
            return float(columns[-1])


def get_psd(folder=None, cumulative=False, network=False, normalize=True):

    cum_string = "_cumulative" if cumulative else ""
    net_string = "Network-accessible_" if network else "Total_"
    file_name = f"{net_string}psd{cum_string}.txt"
    if folder:
        # print(folder)
        file_loc = os.path.join(folder, file_name)
        # print("in here")
    else:
        file_loc = file_name
    # print(file_loc)
    probe_diameter, result = np.genfromtxt(file_loc, unpack=True)

    if normalize:
        result = result / max(result)

    if float(result[-1]) != float(0):
        print(
            f"{file_loc}: Warning, last data point is not zero, consider increasing max probe diameter"
        )
    return probe_diameter, result


def get_probe(cumulative_val, folder=None, network=False):

    probe_diameter, cumulative_intensity = get_psd(folder=folder, cumulative=True, network=network)

    index = np.argmin(np.abs(cumulative_intensity - cumulative_val))
    if index == len(probe_diameter):
        print("Warning, probe size is last data point, consider increasing max probe diameter")

    return probe_diameter[index]


# ===================================WRAPPERS===================================
# the following are wrappers to "automate" some tasks using the above functions
def get_average_data(prop, files_in, network=False):
    """
    Averages a property using all summary.dat files within a specified directory.
    Search includes all subdirectories as well
    """

    data_array = np.array([])

    prop_avg = None
    prop_std = None
    prop_len = None

    subdirs = [root for root, dirs, files in os.walk(files_in)]

    for subdir in subdirs:
        summary_file = os.path.join(subdir, "summary.dat")

        if os.path.isfile(summary_file):
            data = get_data(prop, summary_file)
            data_array = np.append(data_array, data)

    prop_avg = np.average(data_array)
    prop_std = np.std(data_array)
    prop_len = len(data_array)

    return prop_avg, prop_std, prop_len


def get_average_psd(files_in=None, cumulative=False, network=False, normalize=True):

    pore_array = []
    result_array = []

    pore_avg = None
    prop_avg = None
    prop_std = None
    prop_len = None

    subdirs = [root for root, dirs, files in os.walk(files_in)]

    cum_string = "_cumulative" if cumulative else ""
    net_string = "Network-accessible_" if network else "Total_"
    file_name = f"{net_string}psd{cum_string}.txt"

    for subdir in subdirs:

        file = os.path.join(subdir, file_name)
        # print(file)

        if os.path.isfile(file):
            probe_diameter, result = get_psd(subdir, cumulative, network, normalize=False)
            # result_array = np.append(result_array, result)
            result_array.append(result)
            # pore_array = np.append(pore_array, probe_diameter)
            pore_array.append(probe_diameter)
    pore_avg = np.mean(pore_array, 0)
    prop_avg = np.mean(result_array, 0)
    prop_std = np.std(result_array, 0)
    prop_len = len(result_array)

    if float(np.std(np.std(pore_array, 0))) != float(0):
        print("Error: it appears probes are not equal across files")
        return None

    if normalize:
        prop_avg = prop_avg / np.max(prop_avg)
        prop_std = prop_std / np.max(prop_avg)

    return pore_avg, prop_avg, prop_std, prop_len


def get_average_probe(cumulative_val, files_in, network=False):

    data_array = np.array([])

    prop_avg = None
    prop_std = None
    prop_len = None

    subdirs = [root for root, dirs, files in os.walk(files_in)]

    net_string = "Network-accessible_" if network else "Total_"
    file_name = f"{net_string}psd_cumulative.txt"

    for subdir in subdirs:

        file = os.path.join(subdir, file_name)

        if os.path.isfile(file):
            data = get_probe(cumulative_val, subdir, network)
            data_array = np.append(data_array, data)

    prop_avg = np.average(data_array)
    prop_std = np.std(data_array)
    prop_len = len(data_array)

    return prop_avg, prop_std, prop_len
